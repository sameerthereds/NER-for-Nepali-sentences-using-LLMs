{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Set up OpenAI API key\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sneupane/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"\")\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "from mistralai import Mistral\n",
    "# Set up OpenAI API key\n",
    "client_openai=  OpenAI(api_key=\"\",\n",
    ")\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "client_mistral = Mistral(api_key=\"5O\")\n",
    "\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# system_prompt_nepali = \"तपाईं एक उत्कृष्ट भाषाविज्ञ हुनुहुन्छ। \"\n",
    "\n",
    "def generate_NER(model_name,prompt):\n",
    "\n",
    "\n",
    "    generated_text=\"\"\n",
    "\n",
    "    if model_name==\"openai\":\n",
    "        completion = client_openai.chat.completions.create(\n",
    "            model = 'gpt-4o',\n",
    "            messages = [\n",
    "                # {'role':'system',\"content\": \"You are an excellent linguist. \"},\n",
    "            #   {'role':'system',\"content\": \"तपाईं एक उत्कृष्ट भाषाविज्ञ हुनुहुन्छ। \"},\n",
    "                {'role': 'user', 'content':prompt}\n",
    "            ],\n",
    "            # temperature = 0  ,\n",
    "                max_tokens=500,\n",
    "                temperature=0,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  n=1\n",
    "            )\n",
    "\n",
    "        generated_text = completion.choices[0].message.content.strip()\n",
    "\n",
    "    \n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list=[\"Location\",\"Date\",\"Person\",\"Organization\",\"Event\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "  with open(file_path,\"r\") as f:\n",
    "    tokens,labels = [],[]\n",
    "    t,l = [], []\n",
    "    for line in f.readlines():\n",
    "      tmp = line.strip().split()\n",
    "      if len(tmp) == 0:\n",
    "        tokens.append(t)\n",
    "        labels.append(l)\n",
    "        t, l = [], []\n",
    "      else:\n",
    "        t.append(tmp[0])\n",
    "        l.append(tmp[1])\n",
    "    if len(t) > 0:\n",
    "      tokens.append(t)\n",
    "      labels.append(l)\n",
    "    data = tokens,labels\n",
    "    return data\n",
    "\n",
    "def get_news_data_sets():\n",
    "  train_data= parse_file(\"everest-ner/EverestNER-train-bio.txt\")\n",
    "  test_data= parse_file(\"everest-ner/EverestNER-test-bio.txt\")\n",
    "  return train_data,test_data\n",
    "\n",
    "def get_tweets_data_sets():\n",
    "  train_data = parse_file(\"DanfeNER/DanfeNER-train-bio.txt\")\n",
    "  test_data = parse_file(\"DanfeNER/DanfeNER-test-bio.txt\")\n",
    "  return train_data,test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13848, 1950)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train,news_test=get_news_data_sets()\n",
    "news_train_sentences, news_train_labels = news_train\n",
    "news_test_sentences, news_test_labels = news_test\n",
    "len(news_train_sentences),len(news_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio(entity, prediction,original_sentence):\n",
    "    tokens = prediction.split()\n",
    "    original_tokens=original_sentence.split()\n",
    "    bio_labels = []\n",
    "    inside_entity = False  # Tracks if we are inside an entity\n",
    "\n",
    "    for token in tokens:\n",
    "        if '@@' in token and '##' in token:  # Entire entity in one token\n",
    "            bio_labels.append(f\"B-{entity}\")\n",
    "            inside_entity = False\n",
    "        elif '@@' in token:  # Entity begins in this token\n",
    "            bio_labels.append(f\"B-{entity}\")\n",
    "            inside_entity = True\n",
    "        elif '##' in token:  # Entity ends in this token\n",
    "            bio_labels.append(f\"I-{entity}\")\n",
    "            inside_entity = False\n",
    "        else:\n",
    "            if inside_entity:  # Continuation of the entity\n",
    "                bio_labels.append(f\"I-{entity}\")\n",
    "            else:  # Outside of any entity\n",
    "                bio_labels.append(\"O\")\n",
    "    if len(bio_labels)==0:\n",
    "        bio_labels=[\"O\"]*len(original_tokens)\n",
    "\n",
    "    return bio_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sentences(S, T):\n",
    "    \"\"\"\n",
    "    Aligns the predicted sentence T to match the reference sentence S\n",
    "    while preserving special tokens ('@@' and '##') in T.\n",
    "\n",
    "    Parameters:\n",
    "    S (str): The reference sentence.\n",
    "    T (str): The predicted sentence.\n",
    "\n",
    "    Returns:\n",
    "    str: The aligned version of T, matching the structure of S.\n",
    "    \"\"\"\n",
    "    # Split sentences into tokens\n",
    "    s_tokens = S.split()\n",
    "    t_tokens = T.split()\n",
    "\n",
    "    aligned_t_tokens = []\n",
    "    t_index = 0  # Pointer for T tokens\n",
    "\n",
    "    for s_token in s_tokens:\n",
    "        if t_index < len(t_tokens):\n",
    "            t_token = t_tokens[t_index]\n",
    "\n",
    "            # If the current token in T contains special markers, preserve it.\n",
    "            if '@@' in t_token or '##' in t_token:\n",
    "                aligned_t_tokens.append(t_token)\n",
    "                t_index += 1  # Move to the next token in T\n",
    "            else:\n",
    "                # Align tokens from T to match S\n",
    "                if t_token == s_token:\n",
    "                    aligned_t_tokens.append(t_token)\n",
    "                else:\n",
    "                    aligned_t_tokens.append(s_token)\n",
    "                t_index += 1\n",
    "        else:\n",
    "            # If T is shorter than S, pad with tokens from S\n",
    "            aligned_t_tokens.append(s_token)\n",
    "\n",
    "    # Handle any remaining tokens in T after exhausting S\n",
    "    while t_index < len(t_tokens):\n",
    "        aligned_t_tokens.append(t_tokens[t_index])\n",
    "        t_index += 1\n",
    "\n",
    "    # Join aligned tokens back into a sentence\n",
    "    return ' '.join(aligned_t_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_output(output):\n",
    "    prediction = output\n",
    "    \n",
    "    # Check if \"Output:\" is in the prediction and process accordingly\n",
    "    if \"Output:\" in prediction:\n",
    "        prediction = prediction.split(\"Output:\")[1].strip()\n",
    "\n",
    "    if \"नतिजा:\" in prediction:\n",
    "        prediction = prediction.split(\"नतिजा:\")[1].strip()\n",
    "\n",
    "    if \"वाक्य:\" in prediction:\n",
    "        prediction = prediction.split(\"वाक्य:\")[1].strip()\n",
    "    \n",
    "    # Extract portion before \"Note\" if it exists\n",
    "    if \"Note\" in prediction:\n",
    "        prediction = prediction.split(\"Note\", 1)[0].strip()\n",
    "    \n",
    "    # Extract up to the first occurrence of \"।\"\n",
    "    if \"।\" in prediction:\n",
    "        prediction = prediction.split(\"।\", 1)[0] + \"।\"\n",
    "    \n",
    "    # Return the processed prediction\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_path/train_datasets_with_tagging.pkl\", \"rb\") as file:  # \"rb\" stands for read binary\n",
    "    train_datasets_with_tagging = pickle.load(file)\n",
    "\n",
    "with open(\"output_path/test_datasets_with_tagging.pkl\", \"rb\") as file:  # \"rb\" stands for read binary\n",
    "    test_datasets_with_tagging = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_separated={}\n",
    "for sentence in test_datasets_with_tagging:\n",
    "    # if sentence == \"\\' माइती टाढा ।\":\n",
    "        gd=test_datasets_with_tagging[sentence][1]\n",
    "        a={}\n",
    "        for ent in entities_list:\n",
    "            temp=[\"O\"]*len(gd)\n",
    "            pos=[index for index, label in enumerate(gd) if ent in label]\n",
    "            if len(pos)>0:\n",
    "                for i in pos:\n",
    "                    temp[i]=gd[i]\n",
    "            # if len(temp)!=len(gd):\n",
    "                # print(\"I\")\n",
    "            a[ent]=temp\n",
    "        ground_truth_separated[sentence]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth_separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name=\"k_10_semantic_NEP.pkl\"\n",
    "\n",
    "with open(\"output_path/\"+output_file_name , \"rb\") as file:  # \"rb\" stands for read binary\n",
    "    k_10_semantic_NEP = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ती सबै उपहार हरु विद्युतीय लक्कीड्र मार्फत विजेता छनौट गरिए को थियो ।', 'हिजो एकछत्र प्रयोग भए पनि अनलाइन प्रणाली मा सेयर धितोकर्जा को प्रयोग अव्यवहारिक हुन्छ ।', 'चिकित्सा शिक्षा अध्ययनका लागि वार्षिक अर्बौं रुपैयाँ विदेशिने भएका ले त्यस लाई रोक्न जरूरी रहे को र चिकित्सा विधेयक पास भए पछि त्यस्तो अवस्था को अन्त्य हुने उन ले उल्लेख गरे ।', 'केसी समूह को मुख्य आपत्ति विधेयक को बुँदा ७ ( ३ ) मा छ ।', 'पदयात्री हरु सुकेटार बाट पाथीभरा सम्म हिँडेरै ओहोर दोहोर गरेका थिए ।', 'कतार एयरवेज ग्रुप ले चिनियाँ एयरलाइन्स चाइना साउदर्न एयरलाइन्स ग्रुप को पाँच प्रतिशत सेयर स्वामित्व लिए को छ ।', 'छोरा को अहिले को हालखबर सुनाइहँदा मन्त्री मगर ले एक वर्षअघि पति विगोग हुँदा र निर्वाचन मा होमिँदा आफू लाई पीडा र कठिनाइ भएको स्मरण गरिन् ।', 'नदी भित्र पनि दिंदैनन् , कसरी प्रसारण लाइन बनाउनुः कुलमान', 'रियलक राफयल भरान रातो कार्ड खादै मैदान बाट बाहिरिए पनि त्यस को फाइदा उठाउदै इस्पान्योल ले गोल गरे पनि हार टार्न सकेनन् ।', 'विद्यार्थी बेच्ने कारखानावाला ले केसी लाई उचालिरेहका छन् : योगेश भट्टराई', 'नानीछोरी का ससुरा को परिवार को कथा पनि हत्तपत्त सुन्न नपाइने खाल कै छ ।', '३९ औं एक दिवसीय सतक प्रहार गर्ने क्रम मा कोहली ले ११२ बल खेल्दै ५ चौका र २ छक्का सहित १०४ रन बनाएका थिए ।', 'संघीय मामिला तथा सामान्य प्रशासन मन्त्रालय ले समायोजन मा जान चाहेका सचिव को नाम स्वीकृतिका लागि प्रधानमन्त्री तथा मन्त्रीपरिषद् कार्यालय पठाए को थियो ।', 'सर्वोच्च अदालत ले २०७२ साल फागुन ३० गते विजौरी मा भएको सामूहिक बलात्कार काण्ड को मुख्य दोषी ठहर गर्दै चौधरी लाई ९ वर्ष ११ महिना २ दिन कैद सजाय सुनाउँदै ५० हजार जरिवाना समेत तोके को छ ।', 'कांग्रेस ले आफ्ना पूर्वसभापति हरुको नाम मा खुलेका अस्पताल सरकार ले विघटन गर्न लागे को विरोध मा संसद अवरुद्ध गर्दै आए को छ ।', 'बा आ मा भने म लाई कतै नजान भनि खेतबारी तिर लाग्नु भयो ।', 'मै ले पनि टाउ को हल्लाएर बुझे को संकेत गरेँ ।', 'शुक्रबार आफ्नो जन्मदिन को पूर्वसन्ध्या मा उन ले आफ्ना प्रशंसक हरूलाई केहि गर्न लागे को जान कारी दिए की थिइन् ।', 'त्यो पीडा सहन गर्न नसकेर छोरी को मानसिक सन्तुलन खल्बलिए को र उपचार गर्दा पनि जोगाउन नसकिए को बुवा कपिलदेव खनाल ले सेतोपाटी लाई बताए ।', 'यो बराबरी सँगै चेल्सी ले तेस्रो स्थान को म्यानचेस्टर सिटी सँगको अंक दूरी कम गर्ने मौका समेत गुमाए को छ ।', 'मुटु सँगै मृगौला को समेत उपचार हुने थाहा पाएका वली दम्पत्ती बुटवल स्थित गौतमबुद्ध सामुदायिक मुटु अस्पताल मा आए ।', 'एक्सन ड्रमा को सार्वजनिक ट्रेलर मा विक्रम लाई एक गम्भिर एक्सन शैली मा देखाइए को छ ।', 'त्यहीँ को गुठी मा हिसाब हेर्ने काम पनि गर्थे ।', 'प्रधानाध्यापक साह ले भने , ‘ हाम्रो विद्यालय मा छात्र भन्दा छात्रा कै संख्या अत्याधिक छ जस ले छोरी लाई शिक्षा दिन यहाँका नागरिक हरु कति को सजग छन् भन्ने कुरा को स्पष्ट उदाहरण प्रस्तुत गरे को छ ।', 'बैठक ले ‘ नेपाल भ्रमण वर्ष - २०२० ’ लाई सफल बनाउन प्रदेश मा पनि पर्यटन मन्त्री को अध्यक्षता मा समिति बनाउने निर्णय पनि गरे को छ ।', '‘ जिन्दगी खरानी भयो हे बरै बग्यो नि तिरै तिर , जाने लाई हाइसुक्खै भयो हे बरै बाँच्ने लाई पिरैपिर ’ भनै झै हालत मा छन् वैदेशिक रोजगारी मा जाने धेरै को ।', 'र , उस ले धितोपत्र कारोबार कानुन को उल्लंघन गरे को ठहरिन्छ ।', 'गाडी दुर्घटना कै क्रम मा ओलंघन अस्पताल ल्याइए को उन लाई चिकित्सक ले मृत घोषित गरेका थिए ।', '‘ महाधिवेशन गराउन नसक्ने , जिल्ला अधिवेशन र क्याम्पस अधिवेशन गराउन नसक्ने असक्षम नेतृत्व खारेज गर्नुपर्छ , ’ सभापति देउवा सँग नेविसंघ ले माग गरे , ‘ महाधिवेशन र स्ववियु चुनाव मा जित्ने गरी संगठन लाई परिचालन गर्न तदर्थ समिति बनाऔं ।', 'दोस्रो हाफ मा वैकल्पिक खेलाडी को रूपमा मैदान प्रवेश गरेका ग्यारेथ बेल ले ६७ औं मिनेट मा गोल गर्दै रियल लाई ४ – १ को अग्रता दिलाए ।', 'पूर्व सभामुख ओनसरी घर्ती , देव गुरुङ लगायतका नेता हरू आउँदा उनी खुलेयाम उनी हरूसँगै हुँदा पनि प्रहरी ले पक्राउ गर्न नसक्दा आफू हरूलाई दिक्दार लाग्ने गरे को बुढाथोकी ले बताए ।', 'यस्तै जान कारी नेपाल सरकार का मुख्यसचिव ले अर् को मुद्दा मा आयोग लाई गराएका छन् ।', 'आइतबार साँझ प्रधानमन्त्री को सर कारी निवास बालुवाटार मा आयोजित बैठक मा नेपाल विद्यार्थी संघ का सभापति नैनसिंह महर , अखिल की अध्यक्ष नविना लामा सहित विद्यार्थी नेता बालुवाटार पुगेका छन् ।', 'विहीवार दिउँसो २ घण्टा सम्म नेविसंघ ले कांग्रेस कार्यालय घेराउ गरे को हो ।', 'प्रमुख प्रतिपक्षी नेपाली कांग्रेस को अवरोध बीच राष्ट्रिय सभा ले पनि चिकित्सा शिक्षा विधेयक पारित गरे को छ ।', 'राष्ट्रिय योजना आयोग ले १५ औ योजनाका आधारपत्र माथि प्रादेशिक छलफल लाई जारी राखेको छ ।', 'पश्चिमि क्षेत्रका केही स्थान हरूमा तथा मध्य र पूर्वी क्षेत्रका एक वा दुई स्थान मा हल्का वर्षा को सम्भावना छ ।', 'अघिल्लो दिन प्रतितोला ६० हजार ३ सय रुपैयाँ मा कारोबार भएको सुन यस दिन ५९ हजार ८ सय रुपैयाँ मा झरे को नेपाल सुनचाँदी व्यवसायी महासंघ ले जनाए को छ ।', 'पहिलो हाफ मा १ - ० ले अघि रहे को रियल ले दोस्रो हाफ मा थप दुई गोल गर्दै जित सुनिश्चित गर्\\u200dयो ।', 'यो दुई महिना मा ८ वटा शनिबार भएका देशब्यापी प्रदर्शन मा १० जना को मृत्यु भयो , हजारौं पक्राउ परेका छन् ।', 'भोलि सम्म चल्ने उक्त छलफलम मा योजना आयोगका सदस्य शुशिल भट्ट ले नेतृत्व गरेका छन् ।', 'चोभार सुख्खा बन्दरगाह को विरोध मा प्रदर्शन', 'गत वर्ष पाइपलाइन बाट तेल चोरी गर्दा राज्य ले तीन अर्ब अमेरि की डलर बराबर को तेल गुमाए को थियो ।', 'उद्योगी संगको सहकार्य मा यो कार्ययोजना कार्यान्वयन गर्ने नगरपालिका ले जनाए को छ ।', '( – रासस का लागि विशेष प्रतिनिधि तीर्थ भट्टराई - डाभोस )', 'उस ले आफ्नो काम आफैं गर्नुपर्छ ।', 'पर्थ मा जारी सिड्नी सिक्सर्स र पर्थ स्कोर्चर्स बीच खेल मा पर्थ का अनुभवी ब्याट्स्म्यान माइकल क्लिंगर आउट हुँदा विवाद भएको हो ।', 'शनिबार उन ले वेबसाइट सुरू भएको जान कारी दिइन् ।', 'सुरू मा सभामुख कृष्णबहादुर महरा ले प्रश्नोत्तरका लागि अनुमति नदिने बताए ।', 'तर पछिल्ला दिन मा जफत हुने मदिरा को परिमाण घट्दै गए को सापकोटा ले बताए ।', 'अख्तियार ले सिधै अनुसन्धान गर्दा हुने ठाउँ मा आयोग गठन ले एउटै काम मा दोहरोपना आउँछ ।', '५० वर्षिय दधिराम की श्रीमती क्षेत्रकुमारी परियार को पनि पाठेघर को अप्रेसन गरिए को कारण काम गर्न सक्ने अवस्था की छैनन् ।', 'उन को बसाइँ ४ दिन को हुनेछ ।', '९० वर्ष की रत्नदेवी पुराना हिन्दी गीत मा श्रीमान सम्झन्छिन्', 'एकपटक डायलाईसिस गर्न आउँदा दुई दिन बित्छ , दुई दिन होटल मा खाना खाजा खाँदा उत्ति पैसा खर्च हुन्छ , ’ मोहन ले भने ।', 'दोष मुफासा कै सानो छोरा सिम्बा लाई लगाइदिन्छ ।', 'बिदा पुनरावलोकन गर्न गठित कार्यदल ले विभिन्न समुदायका गरी कुल १२ दिन सार्वजनिक बिदा थप गर्ने प्रस्ताव सरकारसक्षम पेस गरे को हो ।', 'बनारसी दोपट्टा मा सजिएर गृहप्रवेश गरिन् दीपिका', 'टाउ को दुख्ने को टाउ को दुखे पनि आफू हरूले मूर्ति जस्तो चुपचाप बस्ने इमान्दार होइन , सक्रिय इमान्दार भएर जनता को मत को जिम्मे वारी पूरा गर्ने बताए ।', 'घोराही उपमहानगरपालिका को विकट वडा नं १९ सैघा की एक किशोरी चार दिन देखि बेपत्ता भएकी छिन् ।', 'त्यस्तै चिया तथा खाजा पसल संचालन गर्न , टेम्पो वा ट्याक्सीका लागि , ठेलागाडा को पसल गर्न , स्टेसनरी तथा साइबर संचालन गर्न ऋण पाइन्छ ।', 'पानीका कारण सन् २०१७ को सुरूआत मा सुजन शर्मा र सुजन अधिकारी ले ज्यान गुमाए लगत्तै २०१८ मा क्रोनोला बिचमा अर् की नेपाली चेली को शव भेटिए को थियो ।', 'मुख्यमन्त्री लालबाबु राउत ले यस प्रदेश मा छोरी हरू पठनपाठन बाट वञ्चित हुँदै आए को भन्दै प्रदेश सरकार ले प्रारम्भिक चरण मा ल्याए को नीति तथा कार्यक्रम मै छोरी हरुलाई पढाउनुपर्छ भन्दै आकर्षक योजना सामेल गर्न समेत लगाए ।', 'संसदीय समिति ले तत्काल छाउ महिला को सुरक्षा को प्रत्याभूति र सो को वातावरण बनाउन नेपाल सरकार , महिला बालबालिका तथा ज्येष्ठ नागरिक मन्त्रालय लाई निर्देशन दिए को छ ।', 'जैन धर्म मा पनि महावीर स्वामी आफैं योगी थिए र उन को समय मा योग को विवेचना बढी भएको पाइन्छ ।', 'न्युजिल्यान्ड यस अघि पहिलो खेल मा श्रीलंका लाई ४५ रन ले हराए को थियो भने दोस्रो खेल मा २१ रन ले पछि पारे को थियो ।', 'यस्तै तुसीपुर – १० की सुशीला खड्का पनि गत कात्तिक २७ गते देखि परिवार को सम्पर्क मा नआए को भन्दै आ मा पीमा वली ले प्रहरी मा जाहेरी गरे की छन् ।', 'यूरोपेली युनियन लगायतका पश्चिमीदेश को वक्तव्य प्रति प्रधानमन्त्री ओली को आपत्ति', 'दाङ को तुलसीपुर स्थित एक घर मा चोरी भएको छ ।', 'आरा प्रयोग गरेर रूख ढालिए पनि गोलिया कसै ले लगे को छैन ।', 'घरायसी सामान किन्न करिब १५ किलोमिटर टाढा घोराही बजार आए की १६ वर्षीया भुमा राहुमगर गत १५ गते देखि बेपत्ता भएकी उन को पारिवारिक स्रोत ले जनाए को छ ।', 'केही छिन पछि म झ्याङखोर्ने भैंसी लाई भेट्न गएँ ।', 'तिमी ले आफ्नो पाडो पनि लिएर आउ है ।', 'युनाइटेड सोसलिस्ट पार्टी अफ भेनेजुयला का नेता मडुरो सन् २०१३ मा सत्ता मा आएका थिए ।', 'एक्कासी काठ को बाकस मा शव आए पछि श्रीमान् घर आउने प्रतीक्षा मा दिन गनेर बसे की जमुना को जीवन कै भरोसा टुट्यो , सहारा गुम्यो ।', 'यही रमझम मा बुधबार हुँदै गरे को अर् को एक बिहे पनि चर्चा मा छ - कमेडियन कपिल शर्मा को ।', 'फ्रान्स मा मुख्य गरि दुई थरि सहरी गुरिल्ला सक्रिय छन्: पहिलो , उग्र वामपन्थि हरू , यिनी हरूले पूँजिवाद लाई नै सबै समस्या को जड मान्छन् ।', 'हेनरी निकोलस ले ८० बल मा १२ चौका र ३ छक्का सहित १ सय २४ रन मा नट आउट रहँदा रोश टेलर ले १ सय ३१ बल मा ९ चौका र ४ छक्का सहित १ सय ३७ रन बनाए ।', 'कल्पना का बुवा शिक्षक थिए ।', 'भारत को उत्तरपूर्वी आसाम लगायत विभिन्न प्रदेश मा दशकौं देखि लाखौं व्यक्ति विभिन्न छिमे की मुलुक बाट आएर बसोबास गरेका छन् ।', 'दुवै ठाउँ बाट ५०० व्यक्ति हरूका लागि कृतिम खुट्टा उपलब्ध गराउने योजना रहे को चौधरी फाउन्डेसन ले जनाए को छ ।', 'यीनै हस्ताक्षर अभियानकर्ता ले प्रथम पटक १७ नोभेम्बर २०१८ , शनिबार पहिलो पटक < आक्ट एक > नाम दिएर देश भर बिरोध प्रदर्शन गरे ।', 'पाँचथर मा मेडिकल कलेज स्थापनाका लागि सम्भाव्यता अध्ययन गरिए को छ ।', 'अण्डा को दरभाउ मा बिचौलिया को प्रभाव हुने हुँदा किसान ले लागत मूल्य नपाए को गुनासो गरेका छन् ।', 'विज्ञप्ति मा दाहाल ले संयुक्त राष्ट्रसंघ लगायत अन्तर्राष्ट्रिय समुदाय लाई सार्वभौमसत्ता को रक्षा गर्ने भेनेजुयला का जनता को कदम साथ दिन पनि आह्वान गरेका छन् ।', 'रियल शीर्ष स्थान को बार्सिलोना भन्दा १० तथा एट्लेटिको मड्रिड भन्दा ५ अंक ले पछि छ ।', 'जबरा ले संसदीय समिति मा धारणा राख्ने र आफू ले सार्वजनिक धारणा राखेको भन्दै जोशी लाई कार्यान्वयनका लागि ‘ इजलास नतोक्ने ’ समझदारी बने को हो ।', 'कार्यक्रम मा नेपाल का लागि भारत ीय राजदूत मन्जीव सिंह पुरी ले विश्व हिन्दी दिवस को अवसर मा भारत का प्रधानमन्त्री नरेन्द्र मोदी को सन्देश पढेर सुनाएका थिए ।', 'निर्माण मजदुर को रुपमा कार्यरत मोहन स्वदेश फर्किएर केहि महिना काठमाडौं मा घर निर्माण मजदुर कै रुपमा काम गरे ।', 'बुझ्दा त भट्टराई लाई त केही पनि थाहा छैन ।', 'तिलोत्तमा नगरपालिका ले रोजगार मूलक उद्योग लाई प्राथमिकता दिँदै विभिन्न योजना अगाडि सारे को छ ।', 'राप्ती आँखा अस्पताल तुलसीपुर रक्षाचौर की नेत्र रोग विशषेज्ञ डा. शुलक्ष्मी कटवाल ले हरेक चालक ले तीन / तीन महिना मा आँखा को चेक जाँच गराउन आवश्यक रहे को तर्क गरिन् ।', 'यस बाट उन को अभिनय को जादु कम भएको आलोचना लाई कंगना ले केहि मानिस हरूले आफ्नो असफलता कुरीरहेका ले यस्ता टिप्पणी भएको बताए की छन् ।', 'अहिले को सन्दर्भ मा संविधान र कानुन मिचेर भ्रष्टाचारी बचाउन नै संविधान विपरित आयोग लाई जाँचबुझ गर्न दिइन लागे को त होइन भन्ने प्रश्न उठे को छ ।', 'सौन्दर्य को माध्यम बाट अन्तर्राष्ट्रिय क्षेत्र मा नेपाल को ख्याति कमाए को भन्दै उन लाई चेम्बर अफ कमर्स ले सम्मान गरे को हो ।', 'सन् २००७ मा १ हजार ७ सय ३० अर्ब अमेरि की डलर लगानी प्रवाह भएको थियो ।', 'ठेक्का पाउना साथ ठेकेदार ले भएको सडक रातारात भत्कायो ।', 'सन् २०२० को अक्टुबर १८ देखि नोभेम्बर १५ सम्म हुने प्रतियोगिता मा १० टिम ले सोझै प्रवेश पाएका हुन् ।', 'तेस्रो स्थान मा रहे को सेभिल्ला को ३३ अंक रहे को छ ।', '३ वर्ष अघि पनि आयोजना को मिलन चौक उत्तर को जंगल मा ३ सय कदमका रूख काटिए को थियो ।']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def select_random_keys(input_dict, num_keys=100, seed=42):\n",
    "    \"\"\"\n",
    "    Selects a specified number of keys randomly from a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        input_dict (dict): The dictionary to sample keys from.\n",
    "        num_keys (int): The number of keys to select.\n",
    "        seed (int): The seed for random number generator.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of randomly selected keys.\n",
    "    \"\"\"\n",
    "    random.seed(seed)  # Set the seed for reproducibility\n",
    "    all_keys = list(input_dict.keys())\n",
    "    \n",
    "    # Ensure the number of keys does not exceed the available keys\n",
    "    if num_keys > len(all_keys):\n",
    "        raise ValueError(\"num_keys exceeds the number of available keys in the dictionary.\")\n",
    "    \n",
    "    return random.sample(all_keys, num_keys)\n",
    "\n",
    " # Example dictionary with 500 keys\n",
    "output_file_name=k_10_semantic_NEP\n",
    "random_keys = select_random_keys(output_file_name, num_keys=100, seed=123)\n",
    "\n",
    "print(random_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_predictions(sentence, ground_truths, predictions):\n",
    "    updated_predictions = {}\n",
    "    all_prompts={}\n",
    "    # Iterate over each entity type in the predictions\n",
    "    for entity_type, prediction in predictions.items():\n",
    "        ground_truth = ground_truths.get(entity_type, [])\n",
    "        updated_predictions[entity_type] = [\"O\"] * len(prediction)\n",
    "        tokens = sentence.split()\n",
    "\n",
    "        i = 0\n",
    "        while i < len(prediction):\n",
    "            if prediction[i].startswith(\"B-\"):\n",
    "                # Start of a new entity span\n",
    "                entity_span = [tokens[i]]\n",
    "                entity_indices = [i]\n",
    "                entity_label = prediction[i][2:]  # Extract the label type\n",
    "\n",
    "                # Collect continuation tokens\n",
    "                j = i + 1\n",
    "                while j < len(prediction) and prediction[j] == f\"I-{entity_label}\":\n",
    "                    entity_span.append(tokens[j])\n",
    "                    entity_indices.append(j)\n",
    "                    j += 1\n",
    "\n",
    "                # Validate the entire entity span\n",
    "                entity_value = \" \".join(entity_span)\n",
    "\n",
    "                # Prompt GPT to validate\n",
    "                # prompt = f\"Is '{entity_value}' a {entity_type} in this sentence: '{sentence}'? Please answer with Yes or No. No explanation is needed.\"\n",
    "                if len(entity_span)>1:\n",
    "                    prompt=f\"The given sentence: {sentence} \\nAre the words {entity_value} in the given sentence a {entity_type} entity? Please answer with Yes or No. No explanation is needed. \"\n",
    "                else:\n",
    "                    prompt=f\"The given sentence: {sentence} \\nIs the word {entity_value} in the given sentence a {entity_type} entity? Please answer with Yes or No. No explanation is needed. \"\n",
    "                # print(prompt)\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    answer=generate_NER(\"openai\",prompt)\n",
    "                    # print(answer)\n",
    "                    all_prompts[prompt]=answer\n",
    "                    # Update the prediction based on GPT's response\n",
    "                    if \"Yes\" in answer:\n",
    "                        # print(\"I came here\")\n",
    "                        for idx in entity_indices:\n",
    "                            updated_predictions[entity_type][idx] = prediction[idx]\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error querying OpenAI: {e}\")\n",
    "                    # updated_predictions[entity_type].append(\"O\")\n",
    "            # else:\n",
    "            #     updated_predictions[entity_type].append(\"O\")\n",
    "            i+=1\n",
    "    return updated_predictions,all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true1=[]\n",
    "y_pred1=[]\n",
    "y_pred2=[]\n",
    "count=0\n",
    "error_sentences={}\n",
    "count=0\n",
    "self_corrections={}\n",
    "original_predictions={}\n",
    "new_predictions={}\n",
    "for sentence in random_keys[:]:\n",
    "    true_label=ground_truth_separated[sentence]\n",
    "    temp={}\n",
    "    temp1={}\n",
    "    temp2={}\n",
    "    for entity in entities_list:\n",
    "\n",
    "        prediction=(output_file_name[sentence][entity])\n",
    "        prediction=post_process_output(prediction)\n",
    "\n",
    "        predicted_sentences=convert_to_bio(entity,prediction,sentence)\n",
    "       \n",
    "        if len(predicted_sentences)==len(true_label[entity]):\n",
    "\n",
    "            y_true1.append(true_label[entity])\n",
    "            y_pred1.append(predicted_sentences)\n",
    "            \n",
    "            validated_predictions,all_prompts = validate_predictions(sentence, {entity:true_label[entity]}, {entity:predicted_sentences})\n",
    "            y_pred2.append(validated_predictions[entity])\n",
    "            temp1[entity]=predicted_sentences\n",
    "            temp2[entity]=validated_predictions\n",
    "            temp[entity]=all_prompts\n",
    "    self_corrections[sentence]=temp\n",
    "    original_predictions[sentence]=temp1\n",
    "    new_predictions[sentence]=temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Date       0.50      0.71      0.59        35\n",
      "       Event       0.07      1.00      0.13         2\n",
      "    Location       0.42      0.88      0.57        24\n",
      "Organization       0.47      0.82      0.60        40\n",
      "      Person       0.78      0.93      0.85        55\n",
      "\n",
      "   micro avg       0.50      0.85      0.63       156\n",
      "   macro avg       0.45      0.87      0.55       156\n",
      "weighted avg       0.58      0.85      0.67       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true1,y_pred1, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Date       0.58      0.20      0.30        35\n",
      "       Event       0.11      1.00      0.19         2\n",
      "    Location       0.58      0.88      0.70        24\n",
      "Organization       0.64      0.72      0.68        40\n",
      "      Person       0.93      0.93      0.93        55\n",
      "\n",
      "   micro avg       0.66      0.71      0.68       156\n",
      "   macro avg       0.57      0.75      0.56       156\n",
      "weighted avg       0.71      0.71      0.68       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true1,y_pred2, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
