{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Set up OpenAI API key\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list=[\"Location\",\"Date\",\"Person\",\"Organization\",\"Event\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "  with open(file_path,\"r\") as f:\n",
    "    tokens,labels = [],[]\n",
    "    t,l = [], []\n",
    "    for line in f.readlines():\n",
    "      tmp = line.strip().split()\n",
    "      if len(tmp) == 0:\n",
    "        tokens.append(t)\n",
    "        labels.append(l)\n",
    "        t, l = [], []\n",
    "      else:\n",
    "        t.append(tmp[0])\n",
    "        l.append(tmp[1])\n",
    "    if len(t) > 0:\n",
    "      tokens.append(t)\n",
    "      labels.append(l)\n",
    "    data = tokens,labels\n",
    "    return data\n",
    "\n",
    "def get_news_data_sets():\n",
    "  train_data= parse_file(\"everest-ner/EverestNER-train-bio.txt\")\n",
    "  test_data= parse_file(\"everest-ner/EverestNER-test-bio.txt\")\n",
    "  return train_data,test_data\n",
    "\n",
    "def get_tweets_data_sets():\n",
    "  train_data = parse_file(\"DanfeNER/DanfeNER-train-bio.txt\")\n",
    "  test_data = parse_file(\"DanfeNER/DanfeNER-test-bio.txt\")\n",
    "  return train_data,test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train,news_test=get_news_data_sets()\n",
    "news_train_sentences, news_train_labels = news_train\n",
    "news_test_sentences, news_test_labels = news_test\n",
    "len(news_train_sentences),len(news_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bio(entity, prediction,original_sentence):\n",
    "    tokens = prediction.split()\n",
    "    original_tokens=original_sentence.split()\n",
    "    bio_labels = []\n",
    "    inside_entity = False  # Tracks if we are inside an entity\n",
    "\n",
    "    for token in tokens:\n",
    "        if '@@' in token and '##' in token:  # Entire entity in one token\n",
    "            bio_labels.append(f\"B-{entity}\")\n",
    "            inside_entity = False\n",
    "        elif '@@' in token:  # Entity begins in this token\n",
    "            bio_labels.append(f\"B-{entity}\")\n",
    "            inside_entity = True\n",
    "        elif '##' in token:  # Entity ends in this token\n",
    "            bio_labels.append(f\"I-{entity}\")\n",
    "            inside_entity = False\n",
    "        else:\n",
    "            if inside_entity:  # Continuation of the entity\n",
    "                bio_labels.append(f\"I-{entity}\")\n",
    "            else:  # Outside of any entity\n",
    "                bio_labels.append(\"O\")\n",
    "    if len(bio_labels)==0:\n",
    "        bio_labels=[\"O\"]*len(original_tokens)\n",
    "\n",
    "    return bio_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bio_labels_with_continuation_priority(lists, tokens):\n",
    "    \"\"\"\n",
    "    Merge BIO labels from multiple lists with continuation priority.\n",
    "    The priority is given to entities with the longest valid continuation.\n",
    "\n",
    "    Args:\n",
    "        lists (list of lists): BIO-tagged lists to merge.\n",
    "        tokens (list): The original tokens for length reference.\n",
    "\n",
    "    Returns:\n",
    "        list: A merged BIO-tagged list with the same length as the tokens.\n",
    "    \"\"\"\n",
    "    # Determine the length of the tokens\n",
    "    sentence_length = len(tokens)\n",
    "\n",
    "    # Initialize a merged list with \"O\"\n",
    "    merged_list = [\"O\"] * sentence_length\n",
    "\n",
    "    # Iterate over all positions in the sentence\n",
    "    for i in range(sentence_length):\n",
    "        # Collect all entities at the current position across all lists\n",
    "        entities_at_position = [\n",
    "            lst[i] if i < len(lst) else \"O\"\n",
    "            for lst in lists\n",
    "        ]\n",
    "\n",
    "        # Filter out \"O\" labels\n",
    "        entities_at_position = [entity for entity in entities_at_position if entity != \"O\"]\n",
    "\n",
    "        if entities_at_position:\n",
    "            # If only one entity is present, choose it\n",
    "            if len(entities_at_position) == 1:\n",
    "                merged_list[i] = entities_at_position[0]\n",
    "            else:\n",
    "                # Handle conflicting entities\n",
    "                continuation_scores = {}\n",
    "                for entity in entities_at_position:\n",
    "                    if entity.startswith(\"B-\"):\n",
    "                        entity_type = entity[2:]\n",
    "                        # Calculate continuation length\n",
    "                        continuation_length = 0\n",
    "                        for lst in lists:\n",
    "                            pos = i\n",
    "                            while pos + 1 < len(lst) and lst[pos + 1] == f\"I-{entity_type}\":\n",
    "                                continuation_length += 1\n",
    "                                pos += 1\n",
    "                        continuation_scores[entity] = continuation_length\n",
    "\n",
    "                # Choose the entity with the longest continuation\n",
    "                if continuation_scores:\n",
    "                    best_entity = max(continuation_scores, key=continuation_scores.get)\n",
    "                    merged_list[i] = best_entity\n",
    "                else:\n",
    "                    # Default to the first valid entity if no continuation\n",
    "                    merged_list[i] = entities_at_position[0]\n",
    "\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sentences(S, T):\n",
    "    \"\"\"\n",
    "    Aligns the predicted sentence T to match the reference sentence S,\n",
    "    ensuring tokens in T match S while preserving the original @@ and ## markers.\n",
    "\n",
    "    Parameters:\n",
    "    S (str): The reference sentence.\n",
    "    T (str): The predicted sentence.\n",
    "\n",
    "    Returns:\n",
    "    str: The aligned version of T, matching the structure of S.\n",
    "    \"\"\"\n",
    "    s_tokens = S.split()\n",
    "    t_tokens = T.split()\n",
    "\n",
    "    aligned_t_tokens = []\n",
    "    t_index = 0\n",
    "\n",
    "    for s_token in s_tokens:\n",
    "        # Track reconstructed token from T\n",
    "        reconstructed_token = \"\"\n",
    "        while t_index < len(t_tokens):\n",
    "            t_token = t_tokens[t_index]\n",
    "            \n",
    "            # Strip @@ and ## for comparison\n",
    "            stripped_token = t_token.replace(\"@@\", \"\").replace(\"##\", \"\")\n",
    "\n",
    "            # Combine tokens from T to match S\n",
    "            if not reconstructed_token:\n",
    "                reconstructed_token = stripped_token\n",
    "            else:\n",
    "                reconstructed_token += stripped_token\n",
    "\n",
    "            t_index += 1\n",
    "\n",
    "            # Check if the reconstructed token matches the current S token\n",
    "            if reconstructed_token == s_token:\n",
    "                # If token was reconstructed, wrap it with @@ and ##\n",
    "                if len(reconstructed_token) > len(t_token):\n",
    "                    aligned_t_tokens.append(f\"@@{reconstructed_token}##\")\n",
    "                else:\n",
    "                    aligned_t_tokens.append(t_token)\n",
    "                break\n",
    "        else:\n",
    "            # If T tokens are exhausted without a match, add S token as is\n",
    "            aligned_t_tokens.append(s_token)\n",
    "\n",
    "    # Handle any remaining tokens in T\n",
    "    while t_index < len(t_tokens):\n",
    "        aligned_t_tokens.append(t_tokens[t_index])\n",
    "        t_index += 1\n",
    "\n",
    "    # Join the aligned tokens into a single string\n",
    "    return ' '.join(aligned_t_tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_output(output):\n",
    "    prediction = output\n",
    "    \n",
    "    # Check if \"Output:\" is in the prediction and process accordingly\n",
    "    if \"Output:\" in prediction:\n",
    "        prediction = prediction.split(\"Output:\")[1].strip()\n",
    "\n",
    "    if \"नतिजा:\" in prediction:\n",
    "        prediction = prediction.split(\"नतिजा:\")[1].strip()\n",
    "\n",
    "    if \"वाक्य:\" in prediction:\n",
    "        prediction = prediction.split(\"वाक्य:\")[1].strip()\n",
    "    \n",
    "    # Extract portion before \"Note\" if it exists\n",
    "    if \"Note\" in prediction:\n",
    "        prediction = prediction.split(\"Note\", 1)[0].strip()\n",
    "    \n",
    "    # Extract up to the first occurrence of \"।\"\n",
    "    if \"।\" in prediction:\n",
    "        prediction = prediction.split(\"।\", 1)[0] + \"।\"\n",
    "    \n",
    "    # Return the processed prediction\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_path/train_datasets_with_tagging.pkl\", \"rb\") as file:  # \"rb\" stands for read binary\n",
    "    train_datasets_with_tagging = pickle.load(file)\n",
    "\n",
    "with open(\"output_path/test_datasets_with_tagging.pkl\", \"rb\") as file:  # \"rb\" stands for read binary\n",
    "    test_datasets_with_tagging = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_separated={}\n",
    "for sentence in test_datasets_with_tagging:\n",
    "    # if sentence == \"\\' माइती टाढा ।\":\n",
    "        gd=test_datasets_with_tagging[sentence][1]\n",
    "        a={}\n",
    "        for ent in entities_list:\n",
    "            temp=[\"O\"]*len(gd)\n",
    "            pos=[index for index, label in enumerate(gd) if ent in label]\n",
    "            if len(pos)>0:\n",
    "                for i in pos:\n",
    "                    temp[i]=gd[i]\n",
    "            # if len(temp)!=len(gd):\n",
    "                # print(\"I\")\n",
    "            a[ent]=temp\n",
    "        ground_truth_separated[sentence]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name=\"pickled_file.pkl\"\n",
    "\n",
    "with open(\"/home/sneupane/NER/Flairs_paper/output/\"+output_file_name , \"rb\") as file:  # \"rb\" stands for read binary\n",
    "    pickled_file = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sentences(S, T):\n",
    "    \"\"\"\n",
    "    Aligns the predicted sentence T to match the reference sentence S\n",
    "    while preserving special tokens ('@@' and '##') in T.\n",
    "\n",
    "    Parameters:\n",
    "    S (str): The reference sentence.\n",
    "    T (str): The predicted sentence.\n",
    "\n",
    "    Returns:\n",
    "    str: The aligned version of T, matching the structure of S.\n",
    "    \"\"\"\n",
    "    # Split sentences into tokens\n",
    "    s_tokens = S.split()\n",
    "    t_tokens = T.split()\n",
    "\n",
    "    aligned_t_tokens = []\n",
    "    t_index = 0  # Pointer for T tokens\n",
    "\n",
    "    for s_token in s_tokens:\n",
    "        if t_index < len(t_tokens):\n",
    "            t_token = t_tokens[t_index]\n",
    "\n",
    "            # If the current token in T contains special markers, preserve it.\n",
    "            if '@@' in t_token or '##' in t_token:\n",
    "                aligned_t_tokens.append(t_token)\n",
    "                t_index += 1  # Move to the next token in T\n",
    "            else:\n",
    "                # Align tokens from T to match S\n",
    "                if t_token == s_token:\n",
    "                    aligned_t_tokens.append(t_token)\n",
    "                else:\n",
    "                    aligned_t_tokens.append(s_token)\n",
    "                t_index += 1\n",
    "        else:\n",
    "            # If T is shorter than S, pad with tokens from S\n",
    "            aligned_t_tokens.append(s_token)\n",
    "\n",
    "    # Handle any remaining tokens in T after exhausting S\n",
    "    while t_index < len(t_tokens):\n",
    "        aligned_t_tokens.append(t_tokens[t_index])\n",
    "        t_index += 1\n",
    "\n",
    "    # Join aligned tokens back into a sentence\n",
    "    return ' '.join(aligned_t_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_f1_merge(output_file_name):\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    y_entity_pred=[]\n",
    "    for sentence in output_file_name:\n",
    "        true_label=test_datasets_with_tagging[sentence][1]\n",
    "        all_predictions=[]\n",
    "        for entity in entities_list:            \n",
    "            prediction=(output_file_name[sentence][entity])        \n",
    "            prediction=post_process_output(prediction)\n",
    "            all_predictions.append(convert_to_bio(entity,prediction,sentence))\n",
    "        merged_predictions=merge_bio_labels_with_continuation_priority(all_predictions,true_label)\n",
    "        \n",
    "        true_label=[item.upper() for item in true_label]\n",
    "        merged_predictions=[item.upper() for item in merged_predictions]\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(merged_predictions)\n",
    "    # print(y_true)\n",
    "    # print(y_pred)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nPrecision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-Score:\", f1_score(y_true, y_pred))\n",
    "    # return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_f1_individual(output_file_name):\n",
    "    y_true1=[]\n",
    "    y_pred1=[]\n",
    "    count=0\n",
    "    error_sentences={}\n",
    "    for sentence in output_file_name:\n",
    "        true_label=ground_truth_separated[sentence]\n",
    "\n",
    "        for entity in entities_list:\n",
    "\n",
    "\n",
    "            prediction=(output_file_name[sentence][entity])\n",
    "            prediction=post_process_output(prediction)\n",
    "\n",
    "            predicted_sentences=convert_to_bio(entity,prediction,sentence)\n",
    "            if len(predicted_sentences)==len(true_label[entity]):\n",
    "\n",
    "                y_true1.append(true_label[entity])\n",
    "                y_pred1.append(predicted_sentences)\n",
    "            else:\n",
    "                # print(len(predicted_sentences),len(true_label[entity]))\n",
    "                # print(entity,true_label[entity],predicted_sentences)\n",
    "                aligned_T = align_sentences(sentence, prediction)\n",
    "                predicted_sentences=convert_to_bio(entity,aligned_T,sentence)\n",
    "                if len(predicted_sentences)==len(true_label[entity]):\n",
    "                    y_true1.append(true_label[entity])\n",
    "                    y_pred1.append(predicted_sentences)\n",
    "                else:\n",
    "                    error_sentences[sentence]=[entity,prediction]\n",
    "                    count+=1\n",
    "    print(classification_report(y_true1, y_pred1))\n",
    "    print(\"\\nPrecision:\", precision_score(y_true1, y_pred1))\n",
    "    print(\"Recall:\", recall_score(y_true1, y_pred1))\n",
    "    print(\"F1-Score:\", f1_score(y_true1, y_pred1))\n",
    "    print(\"Error sentences : \", len(error_sentences))\n",
    "    return error_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
